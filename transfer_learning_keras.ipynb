{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "In the previous notebook we learned how to create custom neural networks using the gluon API. This enabled the creation of custom neural networks, but there is one severly limiting factor no matter the network chosen: a lack of training data.\n",
    "\n",
    "While the power and popularity of neural networks has increased dramatically, the amount of available training data hasn't quite matched pace. This is unfortunate since even the best designed neural network is meaningless without data to train against (excluding some recent developments in reinforcement learning, but we won't talk about that here). While the general availability of labeled data may be small, there are some prominent efforts to create large amounts of labeled data. Since we are focused on images here, the prominent dataset to mention is imagenet. Imagenet is the largest (to the author's knowledge) available labeled image dataset, and models trained on imagenet can be obtained for free and repurposed.\n",
    "\n",
    "This notebook will focus on an idea called transfer learning. The concept is fairly simple. A model trained on one dataset may also be good at understanding another dataset. The power of transfer learning is hard to overstate. While the imagenet dataset is quite impressive, it fails to encompass the entirety of what may be desired of labeled image data. However, if a model trained on imagenet data can be repurposed with great effect, then the value of imagenet is drastically incrased.\n",
    "\n",
    "## Goal\n",
    "In this notebook we will take a model trained on imagenet and repurose the model to perform the same face detection tasks that we built in the previous notebook. While the gluon API will be used, the symbol API will also be leveraged to produce the final output.\n",
    "\n",
    "## Load the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named keras",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3c2cc688cc3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named keras"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import applications\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage import transform\n",
    "from skimage import io\n",
    "from scipy.misc import imresize\n",
    "from glob import glob\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras uses the hdf5 file structure to store it's models. We need to install this package to be able to load a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in /usr/local/lib64/python3.4/site-packages\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/lib64/python3.4/dist-packages (from h5py)\n",
      "Requirement already satisfied: six in /usr/lib/python3.4/dist-packages (from h5py)\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "! source /home/ec2-user/src/anaconda3/bin/activate & sudo pip install h5py\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where are the images?\n",
    "Tell Python where the images are located that we will work with (this assumes that you have not removed the images downloaded in the previous notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base = os.getcwd() # If you manually changed your working directory this will not work\n",
    "old = 'faces' #specify a location to store the images we will work with\n",
    "new = 'bigger_faces'\n",
    "old_loc = os.path.join(base, old)\n",
    "new_loc = os.path.join(base, new)\n",
    "if not os.path.isdir(new_loc):\n",
    "    os.mkdir(new_loc)\n",
    "\n",
    "if not os.path.isdir(os.path.join(new_loc, 'target_ariel')):\n",
    "    os.mkdir(os.path.join(new_loc, 'target_ariel'))\n",
    "\n",
    "positive = os.path.join(new_loc, 'target_ariel', 'positive')\n",
    "negative = os.path.join(new_loc, 'target_ariel', 'negative')\n",
    "if not os.path.isdir(positive):\n",
    "    os.mkdir(positive) #folder to hold all of the pictures of Ariel\n",
    "    \n",
    "if not os.path.isdir(negative):\n",
    "    os.mkdir(negative) #folder to hold pictures of everyone else    \n",
    "    \n",
    "loc = os.path.join(base, old)\n",
    "old_root = os.path.join(loc, 'target_ariel')\n",
    "positive = os.path.join(old_root, 'positive')\n",
    "negative = os.path.join(old_root, 'negative')\n",
    "image_root = old_root.replace(old, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.4/dist-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed image number: 1053\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "#resize the images so that we can use them with a different model\n",
    "files = glob(os.path.join(old_root, '*/*.jpg'))\n",
    "num_images = len(files)\n",
    "for i, file_ in enumerate(files):\n",
    "    img = io.imread(file_)\n",
    "    new_loc = file_.replace(old, new)\n",
    "    new_image = transform.resize(img, (300, 300), mode='constant')\n",
    "    io.imsave(new_loc, new_image)\n",
    "    print('\\rCompleted image number: {}'.format(i), end='')\n",
    "print('\\nfinished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a model from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished downloading\n"
     ]
    }
   ],
   "source": [
    "# If this is your first time running the code, this will take some time to download the parameters\n",
    "inception = applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', input_shape=(300, 300, 3))\n",
    "print('finished downloading')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decapitate the model\n",
    "It sounds rough, but we generally need to decapitate a pretrained model to make use of it. Recall from the model we made in the last notebook, the top layer had one output that was designed to determine if an image was of Ariel or not. This top layer is only useful for the exact problem the model was trained for. But, the same does not hold true for the layers before the top layer!\n",
    "\n",
    "### Stand on the shoulders of giants\n",
    "Think back to the introduction to convolutional layers. The convolutional layer looks for specific patterns in an image. It turns out that in order to understand images, the features of importance can be realtively general amongst image-based tasks. Further, the only layer of a neural network that is not general is the last layer (the one we will remove). This is how we can leverage the immense amount of training that went into making the imagenet model for something that we care about.\n",
    "\n",
    "Thankfully keras has us in mind, and the above command decapitated the model by us simply setting the include top flag to False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create a classifier\n",
    "Here we take the neural network output and we build a simple logistic regression classifier on it. While this isn't the most powerful model on it's own, but with the powerful neural network in front, we'll give it a shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the image information\n",
    "We now need to setup a function that will get the image information and pass it through our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1054 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "batch_size = 50\n",
    "flow = gen.flow_from_directory(image_root, target_size=(300, 300), color_mode='rgb', class_mode='binary',\n",
    "                              shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the shape of the network output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(8), Dimension(8), Dimension(2048)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception.layers[-1].output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished batch number: 21\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "#make an array to hold the neural network output\n",
    "net_output = np.zeros((num_images, 8*8*2048))\n",
    "labels = np.zeros((num_images,))\n",
    "batches = int(np.ceil(num_images/batch_size))\n",
    "low = 0\n",
    "high = 0\n",
    "\n",
    "for i, pic in enumerate(range(batches)):\n",
    "    data = flow.next()\n",
    "    num_samples = data[1].shape[0]\n",
    "    high = low + num_samples\n",
    "    output = inception.predict(data[0])\n",
    "    output = output.reshape((num_samples, -1))\n",
    "    net_output[low:high, :] = output\n",
    "    labels[low:high] = data[1]\n",
    "\n",
    "    low = high\n",
    "    print('\\rFinished batch number: {}'.format(i), end='')\n",
    "    \n",
    "print('\\nComplete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(net_output, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prediction\n",
    "Here we will load an image and make a prediction on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.]\n"
     ]
    }
   ],
   "source": [
    "positives = positive.replace(old, new)\n",
    "\n",
    "pics = glob(os.path.join(positives, '*'))\n",
    "img = io.imread(pics[3])\n",
    "img = np.array(img)\n",
    "img = img.reshape((1, 300, 300, 3))\n",
    "\n",
    "output = inception.predict(img)\n",
    "output = output.flatten()\n",
    "output = output.reshape((1, -1))\n",
    "output = model.predict(output)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
